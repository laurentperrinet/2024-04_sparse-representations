{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Matching Pursuit algorithm is popular in signal processing and applies well to digital images.\n",
    "\n",
    "I have contributed a [python implementation](https://github.com/bicv/SparseEdges) and we will show here how we may use that for extracting a sparse set of edges from an image.\n",
    "\n",
    "* this will be exposed in the following book chapter (see also https://laurentperrinet.github.io/publication/perrinet-15-bicv ), to be published by the end of this year:\n",
    "\n",
    "```bibtex\n",
    "@inbook{Perrinet15bicv,\n",
    "    title = {Sparse models},\n",
    "    author = {Perrinet, Laurent U.},\n",
    "    booktitle = {Biologically-inspired Computer Vision},\n",
    "    chapter = {13},\n",
    "    editor = {Keil, Matthias and Crist\\'{o}bal, Gabriel and Perrinet, Laurent U.},\n",
    "    publisher = {Wiley, New-York},\n",
    "    year = {2015}\n",
    "}\n",
    "```\n",
    "\n",
    "<!-- TEASER_END -->\n",
    "\n",
    "### setting things up\n",
    "\n",
    "We will take some \"baby steps first to show how it works, and then apply that to an image .\n",
    "\n",
    "At first, we will define the [SparseEdges](https://github.com/bicv/SparseEdges) framework which will create the necessary processing steps, from the raw image, to creating the multi-resolution scheme and the Matching Pursuit algorithm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -U NeuroTools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install -U git+https://github.com/bicv/SLIP\n",
    "%pip install -U SLIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install -U git+https://github.com/bicv/LogGabor\n",
    "%pip install -U LogGabor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install -U git+https://github.com/bicv/SparseEdges\n",
    "%pip install -U SparseEdges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-26T10:43:12.346909Z",
     "start_time": "2018-06-26T10:43:09.658784Z"
    }
   },
   "outputs": [],
   "source": [
    "from SparseEdges import SparseEdges\n",
    "mp = SparseEdges('https://raw.githubusercontent.com/bicv/SparseEdges/master/default_param.py')\n",
    "mp.pe.N = 4\n",
    "mp.pe.do_mask = False\n",
    "mp.pe.MP_alpha = 1.\n",
    "mp.pe.do_whitening = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This defines the following set of parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-26T10:43:12.367093Z",
     "start_time": "2018-06-26T10:43:12.353716Z"
    }
   },
   "outputs": [],
   "source": [
    "print('Default parameters: ', mp.pe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The useful imports for a nice notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-26T10:43:12.434926Z",
     "start_time": "2018-06-26T10:43:12.373641Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.rcParams.update({'text.usetex': False})\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "np.set_printoptions(precision=4)#, suppress=True)\n",
    "\n",
    "fig_width = 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-26T10:43:12.452912Z",
     "start_time": "2018-06-26T10:43:12.441774Z"
    }
   },
   "outputs": [],
   "source": [
    "print('Range of spatial frequencies: ', mp.sf_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-26T10:43:12.472686Z",
     "start_time": "2018-06-26T10:43:12.460515Z"
    }
   },
   "outputs": [],
   "source": [
    "print('Range of angles (in degrees): ', mp.theta*180./np.pi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### testing one step of (Matching + Pursuit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we will synthesize an image using 2 [log-Gabor](https://github.com/bicv/LogGabor/) filters and check that they are correctly retrieved using a few Matching Pursuit steps. An edge will be represented by a ``nd.array`` with respectively ``[x position, y center position, indice of angle in multi resolution, index of scale in multi resolution scheme]`` and a coefficient (a complex number whose argument determines the phase of the log-Gabor filter):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-26T10:43:12.488321Z",
     "start_time": "2018-06-26T10:43:12.478395Z"
    }
   },
   "outputs": [],
   "source": [
    "# one\n",
    "edge_in, C_in= [3*mp.pe.N_X/4, mp.pe.N_Y/2, 2, 2], 42\n",
    "# the second\n",
    "edge_bis, C_bis = [mp.pe.N_X/8, mp.pe.N_Y/4, 8, 4], 4.*np.sqrt(2)*np.exp(1j*np.pi/4.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which results in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-26T10:43:15.797097Z",
     "start_time": "2018-06-26T10:43:12.496303Z"
    }
   },
   "outputs": [],
   "source": [
    "# filters in Fourier space\n",
    "FT_lg_in = mp.loggabor(edge_in[0], edge_in[1], sf_0=mp.sf_0[edge_in[3]],\n",
    "                         B_sf=mp.pe.B_sf, theta= mp.theta[edge_in[2]], B_theta=mp.pe.B_theta)\n",
    "FT_lg_bis = mp.loggabor(edge_bis[0], edge_bis[1], sf_0=mp.sf_0[edge_bis[3]],\n",
    "                         B_sf=mp.pe.B_sf, theta= mp.theta[edge_bis[2]], B_theta=mp.pe.B_theta)\n",
    "# mixing both and shows one\n",
    "FT_lg_ = C_in *  FT_lg_in + C_bis * FT_lg_bis\n",
    "image = mp.invert(FT_lg_)\n",
    "\n",
    "_ = mp.show_FT(FT_lg_, axis=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We may start by computing the linear coefficients in the multi resolution scheme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-26T10:43:22.628174Z",
     "start_time": "2018-06-26T10:43:15.803842Z"
    }
   },
   "outputs": [],
   "source": [
    "C = mp.linear_pyramid(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These coefficients correspond to a measure of how well the image matches with the filters in the multi-resolution scheme. These will be used in the **Matching** step.\n",
    "We then detect the best match corresponding to the coefficient with maximum absolute activity:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-26T10:43:23.130708Z",
     "start_time": "2018-06-26T10:43:22.633075Z"
    }
   },
   "outputs": [],
   "source": [
    "edge_star = mp.argmax(C)\n",
    "print('Coordinates of the maximum ', edge_star, ', true value: ', edge_in)\n",
    "print('Value of the maximum ', C[edge_star], ', true value: ', C_in)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this particular orientation and scale, the absolute activity looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-26T10:43:26.008295Z",
     "start_time": "2018-06-26T10:43:23.137007Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, a1, a2 = mp.show_spectrum(np.absolute(C[:, :, edge_star[2], edge_star[3]]), axis=True)\n",
    "_ = a2.plot([edge_star[1]], [edge_star[0]], 'r*')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On our image, this looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-26T10:43:29.001158Z",
     "start_time": "2018-06-26T10:43:26.015024Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, a1, a2 = mp.show_spectrum(image, axis=True)\n",
    "_ = a2.plot([edge_star[1]], [edge_star[0]], 'r*')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now extract and show the \"winner\" of the **Matching** Step:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-26T10:43:32.201646Z",
     "start_time": "2018-06-26T10:43:29.006905Z"
    }
   },
   "outputs": [],
   "source": [
    "FT_star = mp.loggabor(edge_star[0], edge_star[1], sf_0=mp.sf_0[edge_star[3]],\n",
    "                         B_sf=mp.pe.B_sf, theta= mp.theta[edge_star[2]], B_theta=mp.pe.B_theta)\n",
    "im_star = mp.invert(FT_star)\n",
    "_ = mp.show_FT(FT_star, axis=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, it looks like we have extracted the first edge. Let's first check that the energy of\n",
    " - the sum the extracted component  energy, \n",
    " - maximum of its power spectrum (equivalent to the above, but we just check),\n",
    " - half the mean spectrum energy (half? rememeber the trick used in Log-Gabor filters)\n",
    "are all equal to one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-26T10:43:32.239862Z",
     "start_time": "2018-06-26T10:43:32.207398Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(np.sum(im_star**2), mp.FTfilter(im_star, FT_star).max(), np.mean(np.abs(FT_star)**2)/2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's overlay the extracted edge on the image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-26T10:43:36.076638Z",
     "start_time": "2018-06-26T10:43:32.244707Z"
    }
   },
   "outputs": [],
   "source": [
    "edge_star_in = np.array([edge_star[0], edge_star[1], mp.theta[edge_in[2]], mp.sf_0[edge_star[3]], np.absolute(C[edge_star]), np.angle(C[edge_star])])\n",
    "mp.pe.figsize_edges = 9\n",
    "fig, a = mp.show_edges(edge_star_in[:, np.newaxis], image=image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we may substract the residual from the image, it is the **Pursuit** step:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-26T10:43:39.242620Z",
     "start_time": "2018-06-26T10:43:36.083610Z"
    }
   },
   "outputs": [],
   "source": [
    "image_res = (image - C[edge_star] * im_star).real \n",
    "fig, a1, a2 = mp.show_spectrum(image_res, axis=True)\n",
    "_ = a2.plot([edge_star[1]], [edge_star[0]], 'r*')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks pretty clear now that only the second edge remains.\n",
    "We may now repeat another **Matching** step on the residual image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-26T10:43:47.238596Z",
     "start_time": "2018-06-26T10:43:39.248644Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "C = mp.linear_pyramid(image_res)\n",
    "edge_star_bis = mp.argmax(C)\n",
    "print('Coordinates of the maximum ', edge_star_bis, ', true value: ', edge_bis)\n",
    "print('Value of the maximum ', C[edge_star_bis], ', true value: ', C_bis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: to store the complex value of the coefficient, we use the fact that it is easy to transform a complex number to 2 reals and back:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-26T10:43:47.256392Z",
     "start_time": "2018-06-26T10:43:47.245552Z"
    }
   },
   "outputs": [],
   "source": [
    "z = np.sqrt(2)*np.exp(1j*np.pi/4.)\n",
    "z_, z_p = np.absolute(z), np.angle(z)\n",
    "print(z, z_*np.exp(1j*z_p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the linear coefficients corresponding to the first winning filter are canceled:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-26T10:43:47.277002Z",
     "start_time": "2018-06-26T10:43:47.265070Z"
    }
   },
   "outputs": [],
   "source": [
    "print('Value of the residual ', C[edge_star], ', initial value: ', C_in)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's overlay the extracted edge on the image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-26T10:43:50.177137Z",
     "start_time": "2018-06-26T10:43:47.282498Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, a1, a2 = mp.show_spectrum(image_res, axis=True)\n",
    "_ = a2.plot([edge_star_bis[1]], [edge_star_bis[0]], 'r*')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have well extracted the two edges:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-26T10:43:54.178001Z",
     "start_time": "2018-06-26T10:43:50.185434Z"
    }
   },
   "outputs": [],
   "source": [
    "edge_stars = np.vstack((edge_star_in,\n",
    "                        np.array([edge_star_bis[0], edge_star_bis[1], mp.theta[edge_star_bis[2]], mp.sf_0[edge_star_bis[3]], np.absolute(C[edge_star_bis]), np.angle(C[edge_star_bis])])))\n",
    "print(edge_stars)\n",
    "mp.pe.figsize_edges = 9\n",
    "fig, a = mp.show_edges(edge_stars.T, image=image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### testing four steps of Matching Pursuit\n",
    "\n",
    "Let's redo these steps using the ``run_mp`` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-26T10:43:54.256772Z",
     "start_time": "2018-06-26T10:43:54.185367Z"
    }
   },
   "outputs": [],
   "source": [
    "# filters in Fourier space\n",
    "FT_lg_in = mp.loggabor(edge_in[0], edge_in[1], sf_0=mp.sf_0[edge_in[3]],\n",
    "                         B_sf=mp.pe.B_sf, theta= mp.theta[edge_in[2]], B_theta=mp.pe.B_theta)\n",
    "FT_lg_bis = mp.loggabor(edge_bis[0], edge_bis[1], sf_0=mp.sf_0[edge_bis[3]],\n",
    "                         B_sf=mp.pe.B_sf, theta= mp.theta[edge_bis[2]], B_theta=mp.pe.B_theta)\n",
    "# mixing both and shows one\n",
    "FT_lg_ = C_in *  FT_lg_in + C_bis * FT_lg_bis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-26T10:43:55.752900Z",
     "start_time": "2018-06-26T10:43:54.262510Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = mp.show_FT(FT_lg_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-26T10:44:36.038629Z",
     "start_time": "2018-06-26T10:43:55.758332Z"
    }
   },
   "outputs": [],
   "source": [
    "image = mp.invert(FT_lg_)\n",
    "edges, C_res = mp.run_mp(image, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-26T10:44:39.951517Z",
     "start_time": "2018-06-26T10:44:36.047571Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, a = mp.show_edges(edges, image=image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing edge detection on a natural image\n",
    "\n",
    "trying out on a [flikr image from @Doug88888](https://www.flickr.com/photos/doug88888/6370387703):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-26T10:44:40.716884Z",
     "start_time": "2018-06-26T10:44:39.956844Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!curl https://farm7.staticflickr.com/6058/6370387703_5e718ea681_q_d.jpg -o files/6370387703_5e718ea681_q_d.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-26T10:44:40.928529Z",
     "start_time": "2018-06-26T10:44:40.726702Z"
    }
   },
   "outputs": [],
   "source": [
    "%ls -l files/MPtutorial*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %rm files/MPtutorial.npy  files/MPtutorial_MSE.npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %rm files/MPtutorial_MSE.npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-26T10:44:41.549594Z",
     "start_time": "2018-06-26T10:44:40.936186Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from SparseEdges import SparseEdges\n",
    "mp = SparseEdges('https://raw.githubusercontent.com/bicv/SparseEdges/master/default_param.py')\n",
    "if not mp.pe.do_whitening: print('\\!/ Wrong parameters... \\!/')\n",
    "    \n",
    "# where should we store the data + figures generated by this notebook\n",
    "import os\n",
    "name = 'MPtutorial'\n",
    "mp.pe.matpath, mp.pe.figpath = 'files', 'files'\n",
    "mp.pe.do_mask = True\n",
    "\n",
    "mp.pe.N = 2048\n",
    "mp.pe.MP_alpha = 1.\n",
    "mp.pe.MP_alpha = .8\n",
    "\n",
    "mp.pe.mask_exponent = 6.\n",
    "\n",
    "mp.init()\n",
    "\n",
    "# defining input image (get it @ https://www.flickr.com/photos/doug88888/6370387703)\n",
    "#image = mp.imread('https://farm7.staticflickr.com/6058/6370387703_5e718ea681_q_d.jpg')\n",
    "image = mp.imread(os.path.join(mp.pe.matpath, '6370387703_5e718ea681_q_d.jpg'))\n",
    "\n",
    "white = mp.pipeline(image, do_whitening=True)\n",
    "\n",
    "import os\n",
    "matname = os.path.join(mp.pe.matpath, name + '.npy')\n",
    "\n",
    "try:\n",
    "    edges = np.load(matname)\n",
    "except:\n",
    "    edges, C_res = mp.run_mp(white, verbose=True)\n",
    "    np.save(matname, edges)    \n",
    "\n",
    "matname_MSE = os.path.join(mp.pe.matpath, name + '_MSE.npy')\n",
    "try:\n",
    "    MSE = np.load(matname_MSE)\n",
    "except:\n",
    "    MSE = np.ones(mp.pe.N)\n",
    "    image_rec = np.zeros_like(image)\n",
    "    for i_N in range(mp.pe.N):\n",
    "        MSE[i_N] =  ((white-image_rec)**2).sum()\n",
    "        image_rec += mp.reconstruct(edges[:, i_N][:, np.newaxis])\n",
    "        \n",
    "    np.save(matname_MSE, MSE)        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Showing the original image with the edges overlaid:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-26T10:44:49.224156Z",
     "start_time": "2018-06-26T10:44:41.558450Z"
    }
   },
   "outputs": [],
   "source": [
    "#edges = np.load(matname)\n",
    "\n",
    "fig_width_pt = 318.670  # Get this from LaTeX using \\showthe\\columnwidth\n",
    "inches_per_pt = 1.0/72.27               # Convert pt to inches\n",
    "fig_width = fig_width_pt*inches_per_pt  # width in inches\n",
    "mp.pe.figsize_edges = .382 * fig_width  # useful for papers\n",
    "mp.pe.figsize_edges = 9 # useful in notebooks\n",
    "mp.pe.line_width = 1.\n",
    "mp.pe.scale = 1.\n",
    "fig, a = mp.show_edges(edges, image=image, show_phase=True, show_mask=True)\n",
    "#mp.savefig(fig, name + '_rec')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A nice property of Matching Pursuit is that one can reconstruct the image from the edges:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-26T10:45:03.415205Z",
     "start_time": "2018-06-26T10:44:49.238926Z"
    }
   },
   "outputs": [],
   "source": [
    "image_rec = mp.reconstruct(edges)\n",
    "print('remaining energy  = ', ((white-image_rec)**2).sum()/(white**2).sum()*100, '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The whitened reconstructed image looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-26T10:45:10.698534Z",
     "start_time": "2018-06-26T10:45:03.421865Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, a = mp.show_edges(edges, image=image_rec);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Knowing that we may reconstructing back a non-whitened image by applying the inverse filter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-26T10:45:18.114739Z",
     "start_time": "2018-06-26T10:45:10.704506Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, a = mp.show_edges(edges, image=mp.dewhitening(white));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we may reconstruct the image estimated from the edges:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-26T10:45:25.481145Z",
     "start_time": "2018-06-26T10:45:18.122888Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, a = mp.show_edges(edges, image=mp.dewhitening(image_rec));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another nice property of Matching Pursuit is that one may guess the reconstructed error just from the coefficients, without having to actually reconstruct the image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-26T10:45:27.899240Z",
     "start_time": "2018-06-26T10:45:25.486378Z"
    }
   },
   "outputs": [],
   "source": [
    "# checking the quick computation of the MSE in MP\n",
    "MSE_0 = (white**2).sum()\n",
    "print('stats on white:', white.mean(), white.std(), np.sqrt(MSE_0), np.sqrt(MSE[0]))\n",
    "print ('mp.pe.MP_alpha=', mp.pe.MP_alpha)    \n",
    "MP_alpha = 1.2 #mp.pe.MP_alpha\n",
    "MSE_MP = np.ones(mp.pe.N)\n",
    "MSE_MP[1:] = 1. - np.cumsum(edges[4, :-1]**2) / MSE_0  * (2 -  mp.pe.MP_alpha)/mp.pe.MP_alpha\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.subplot(111)\n",
    "plt.plot(np.sqrt(MSE/MSE[0]), 'ro', label='true', alpha=.2)\n",
    "plt.plot(np.sqrt(MSE_MP), 'g--', label='MP-vec', lw=2)\n",
    "plt.xlim([0, mp.pe.N])\n",
    "plt.ylim([0, 1])\n",
    "plt.xlabel('# atoms')\n",
    "plt.ylabel('MSE')\n",
    "_ = plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the representation is extremly sparse:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-26T10:45:27.918284Z",
     "start_time": "2018-06-26T10:45:27.905963Z"
    }
   },
   "outputs": [],
   "source": [
    "print('Total number of coefficients:', int(mp.oc))\n",
    "print('Number of active coefficients:', mp.pe.N)\n",
    "print('Ratio of active coefficients:', (mp.pe.N/mp.oc)*100., '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These coefficients can be plotted on the multiresolution representation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-26T10:45:31.478716Z",
     "start_time": "2018-06-26T10:45:27.925818Z"
    }
   },
   "outputs": [],
   "source": [
    "opts= {'vmin':0., 'vmax':1., 'interpolation':'nearest', 'origin':'upper'}\n",
    "\n",
    "fig_width = 14\n",
    "phi = (np.sqrt(5) +1.)/2. # golden number\n",
    "fig = plt.figure(figsize=(fig_width, fig_width/phi))\n",
    "xmin, ymin, size = 0, 0, 1.\n",
    "\n",
    "C_sparse = np.zeros((mp.pe.N_X, mp.pe.N_Y, mp.pe.n_theta, mp.n_levels))\n",
    "\n",
    "for edge in edges.T:\n",
    "    x, y, theta, sf, coeff, phase = edge\n",
    "    i_theta = np.argmax(mp.theta == theta)\n",
    "    level = np.argmax(mp.sf_0 == sf)\n",
    "    C_sparse[int(x), int(y), i_theta, level] += coeff\n",
    "    \n",
    "fig, axs = mp.golden_pyramid(C_sparse);\n",
    "\n",
    "#mp.savefig(fig, name + '_pyr');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voil√†, hope you liked this introduction! Please leave comments below if you have any question regarding this post.\n",
    "\n",
    "### Showing progressive reconstruction\n",
    "\n",
    "Below, we show that a nice property of Matching Pursuit is that it allows to progressively reconstruct the image. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-26T10:45:31.546339Z",
     "start_time": "2018-06-26T10:45:31.485145Z"
    }
   },
   "outputs": [],
   "source": [
    "image_true = mp.dewhitening(white)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-26T10:46:27.584344Z",
     "start_time": "2018-06-26T10:45:31.553325Z"
    }
   },
   "outputs": [],
   "source": [
    "list_of_number_of_edge = [ 0, 1, 2, 4, 8, 16, 32, 64, 128, 256, 512, 1024, 2048] # np.logspace(1, 10, 10, base=2) #\n",
    "\n",
    "fig_width = 14\n",
    "vmax = 1.\n",
    "fig, axs = plt.subplots(len(list_of_number_of_edge), 2, figsize=(fig_width, fig_width/2*len(list_of_number_of_edge)))\n",
    "vmax = image.max()\n",
    "for i_ax, number_of_edge in enumerate(list_of_number_of_edge):\n",
    "    edges_ = edges[:, :number_of_edge][..., np.newaxis]\n",
    "    image_rec = mp.dewhitening(mp.reconstruct(edges_))\n",
    "    fig, axs[i_ax, 0] = mp.imshow((image_true-image_rec)/vmax, fig=fig, ax=axs[i_ax, 0], norm=False)\n",
    "    axs[i_ax, 0].text(96, 144, 'N=%d' % number_of_edge, color='red', fontsize=32)\n",
    "    fig, axs[i_ax, 1] = mp.imshow((image_rec), fig=fig, ax=axs[i_ax, 1], norm=False)\n",
    "    plt.tight_layout()\n",
    "\n",
    "#mp.savefig(fig, name + '_rec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-26T10:47:16.705396Z",
     "start_time": "2018-06-26T10:46:27.591062Z"
    }
   },
   "outputs": [],
   "source": [
    "list_of_number_of_edge = [ 0, 1, 2, 4, 8, 16, 32, 64, 128, 256, 512, 1024, 2048] # np.logspace(1, 10, 10, base=2) #\n",
    "\n",
    "fig_width = 14\n",
    "vmax = 1.\n",
    "vmax = image.max()\n",
    "for number_of_edge in list_of_number_of_edge:\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(fig_width, fig_width/2))\n",
    "    edges_ = edges[:, :number_of_edge][..., np.newaxis]\n",
    "    image_rec = mp.dewhitening(mp.reconstruct(edges_))\n",
    "    fig, axs[0] = mp.imshow((image_true-image_rec)/vmax, fig=fig, ax=axs[0], norm=False)\n",
    "    axs[0].text(96, 144, 'N=%d' % number_of_edge, color='red', fontsize=32)\n",
    "    fig, axs[1] = mp.imshow((image_rec), fig=fig, ax=axs[1], norm=False)\n",
    "    plt.tight_layout()\n",
    "    #mp.savefig(fig, 'MP_' + str(number_of_edge), formats=['png'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -U moviepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-26T10:47:56.358254Z",
     "start_time": "2018-06-26T10:47:16.711322Z"
    }
   },
   "outputs": [],
   "source": [
    "import moviepy.editor as mpy\n",
    "from moviepy.video.io.bindings import mplfig_to_npimage\n",
    "\n",
    "def make_frame_mpl(i_frame):\n",
    "    fig_mpl, ax = plt.subplots(1, figsize=(5, 5), facecolor='white')\n",
    "    ax = fig_mpl.add_axes([0., 0., 1., 1.], facecolor='w')\n",
    "    ax.cla()\n",
    "    plt.setp(ax, xticks=[])\n",
    "    plt.setp(ax, yticks=[])\n",
    "    #ax.axis(c='b', lw=0, frame_on=False)\n",
    "    # ax.grid(b=False, which=\"both\")\n",
    "    number_of_edge = list_of_number_of_edge[int(i_frame)]\n",
    "    edges_ = edges[:, :number_of_edge][..., np.newaxis]\n",
    "    image_rec = mp.dewhitening(mp.reconstruct(edges_))\n",
    "    fig_mpl, ax = mp.imshow((image_rec)/vmax, fig=fig_mpl, ax=ax, norm=False)\n",
    "    ax.text(96, 144, 'N=%d' % number_of_edge, color='red', fontsize=32)\n",
    "    return mplfig_to_npimage(fig_mpl) # RGB image of the figure\n",
    "\n",
    "animation = mpy.VideoClip(make_frame_mpl, duration=len(list_of_number_of_edge))\n",
    "# animation.ipython_display(fps=1.0, loop=1, autoplay=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-26T10:48:32.209857Z",
     "start_time": "2018-06-26T10:47:56.366198Z"
    }
   },
   "outputs": [],
   "source": [
    "_ = animation.write_videofile(os.path.join(mp.pe.figpath, name + '_rec.mp4'), fps=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-26T10:48:32.612961Z",
     "start_time": "2018-06-26T10:48:32.216799Z"
    }
   },
   "outputs": [],
   "source": [
    "!ffmpeg -y -i files/MPtutorial_rec.mp4 files/MPtutorial_rec.gif"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## some book keeping for the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -U watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-26T10:49:23.008381Z",
     "start_time": "2018-06-26T10:49:22.924505Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext watermark\n",
    "%watermark -i -h -m -v -p numpy,scipy,matplotlib  -r -g -b"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
