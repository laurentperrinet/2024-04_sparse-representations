{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convolutions are essential components of any neural networks, image processing, computer vision ... but these are also a bottleneck in terms of computations... I will here benchmark different solutions using ``numpy``, ``scipy`` or ``pytorch``. This is work-in-progress, so that any suggestion is welcome, for instance on [StackExchange](https://dsp.stackexchange.com/questions/43953/looking-for-fastest-2d-convolution-in-python-on-a-cpu) or in the comments below this post.\n",
    "\n",
    "<!-- TEASER_END -->\n",
    "\n",
    "Let's first initialize the notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division, print_function\n",
    "import numpy as np\n",
    "np.set_printoptions(precision=6, suppress=True)\n",
    "import os\n",
    "%matplotlib inline\n",
    "#%config InlineBackend.figure_format='retina'\n",
    "# %config InlineBackend.figure_format = 'svg'\n",
    "import matplotlib.pyplot as plt\n",
    "phi = (np.sqrt(5)+1)/2\n",
    "fig_width = 10\n",
    "figsize = (fig_width, fig_width/phi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -U scikit-image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# setting up the problem\n",
    "\n",
    "The convolution operates on two 2-D matrices. We will here always consider the case which is most typical in computer vision:\n",
    "\n",
    " - a first matrix $A$ is the input and is typically large ($N \\times N$ where $N$ is typically larger than $2^{10}=1024$),\n",
    " - a second matrix $B$ is the template and is typically smaller (say $M=128$),\n",
    " - the result of the convolution $C = A \\ast B$ is padded such that it is of the same size as $A$.\n",
    " \n",
    " Often, you need to do that with many images on many kernels. In addition, we will test for the effect of [prefetching]( https://github.com/scikit-image/scikit-image/blob/76fe5a3aba599e7ead9dc1a08b242369c947757b/doc/source/user_guide/numpy_images.rst#notes-on-array-order).\n",
    " \n",
    " Let's write a small function for this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N, n_N, M, n_M = 1024, 2, 16, 3\n",
    "# DEBUG \n",
    "# N, n_N, M, n_M = 64, 10, 32, 8\n",
    "\n",
    "def get_data(N=N, n_N=n_N, M=M, n_M=n_M, seed=42, prefetching=False):\n",
    "    np.random.seed(seed)\n",
    "    if prefetching:\n",
    "        A = np.random.rand(n_N, N, N)\n",
    "        B = np.random.rand(n_M, M, M)\n",
    "        C = np.zeros((n_N, n_M, N, N))\n",
    "    else:\n",
    "        A = np.random.rand(N, N, n_N)\n",
    "        B = np.random.rand(M, M, n_M)\n",
    "        C = np.zeros((N, N, n_N, n_M))\n",
    "    return A, B, C\n",
    "\n",
    "for prefetching in [True, False]:\n",
    "    print ('with prefetching=', prefetching)\n",
    "    A, B, C = get_data(prefetching=prefetching)\n",
    "    print('Checking size of A =', A.shape, ' of B=', B.shape, ', and of C=', C.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The call to this function will generate some initialization time, but makes further tests cleaner:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_get_data(N=N, n_N=n_N, M=M, n_M=n_M):\n",
    "    A, B, C = get_data(N, n_N, M, n_M)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "test_get_data(N, n_N, M, n_M)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# using scipy\n",
    "\n",
    "The ``scipy`` library as different solutions:\n",
    "\n",
    "https://docs.scipy.org/doc/scipy/reference/generated/scipy.signal.convolve2d.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import convolve2d\n",
    "def test_scipy(A, B, C, prefetching=False):\n",
    "    if prefetching:\n",
    "        for i_N in np.arange(A.shape[0]):\n",
    "            for i_M in np.arange(B.shape[0]):\n",
    "                C[i_N, i_M, :, :] = convolve2d(A[i_N, :, :], B[i_M, :, :], mode='same', boundary='fill', fillvalue=0)\n",
    "    else:\n",
    "        for i_N in np.arange(A.shape[-1]):\n",
    "            for i_M in np.arange(B.shape[-1]):\n",
    "                C[:, :, i_N, i_M] = convolve2d(A[:, :, i_N], B[:, :, i_M], mode='same', boundary='fill', fillvalue=0)                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A, B, C = get_data(N, n_N, M, n_M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "test_scipy(A, B, C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A, B, C = get_data(N, n_N, M, n_M, prefetching=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "test_scipy(A, B, C, prefetching=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A, B, C = get_data(N, n_N, M, n_M)\n",
    "from scipy.signal import fftconvolve\n",
    "def test_scipy_fft(A, B, C, prefetching=False):\n",
    "    if prefetching:\n",
    "        for i_N in np.arange(A.shape[0]):\n",
    "            for i_M in np.arange(B.shape[0]):\n",
    "                C[i_N, i_M, :, :] = fftconvolve(A[i_N, :, :], B[i_M, :, :], mode='same')\n",
    "    else:\n",
    "        for i_N in np.arange(A.shape[-1]):\n",
    "            for i_M in np.arange(B.shape[-1]):\n",
    "                C[:, :, i_N, i_M] = fftconvolve(A[:, :, i_N], B[:, :, i_M], mode='same')                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A, B, C = get_data(N, n_N, M, n_M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "test_scipy_fft(A, B, C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A, B, C = get_data(N, n_N, M, n_M, prefetching=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "test_scipy_fft(A, B, C, prefetching=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fruther profiling, shows that most of the computing time is divided between the three FFT (2 forward, one inverse):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This shows the advantage of using the Fourier transform to perform the convolution. There is also a slight advantage in using prefetching. However, this solution imposes to have periodic bounds for the borders.\n",
    "\n",
    "# using directly numpy\n",
    "\n",
    "Instead of loading ``scipy`` (or more reasonably just the subset that loads the fftpack), one can simply use ``numpy`` (see this comment by [FonderPrism](http://disq.us/url?impression=edac85da-e7ec-11e8-a90d-002590853080&thread=6169151214&forum=2777256&url=http%3A%2F%2Flaurentperrinet.github.io%2Fsciblog%2Fposts%2F2017-09-20-the-fastest-2d-convolution-in-the-world.html%23comment-4194226955%3A2r-QLLbJUDTFTgvUvpSD8uYz2O4&variant=active&experiment=digests&behavior=click&post=4194226955&type=notification.post.moderator&event=email)).\n",
    "\n",
    "The idea is to simply load the appropriate library which is documented @\n",
    "https://docs.scipy.org/doc/numpy/reference/generated/numpy.fft.fft2.html :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A, B, C = get_data(N, n_N, M, n_M)\n",
    "from numpy.fft  import fft2, ifft2\n",
    "def np_fftconvolve(A, B):\n",
    "    return np.real(ifft2(fft2(A)*fft2(B, s=A.shape)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_numpy_fft(A, B, C, prefetching=False):\n",
    "    if prefetching:\n",
    "        for i_N in np.arange(A.shape[0]):\n",
    "            for i_M in np.arange(B.shape[0]):\n",
    "                C[i_N, i_M, :, :] = np_fftconvolve(A[i_N, :, :], B[i_M, :, :])\n",
    "    else:\n",
    "        for i_N in np.arange(A.shape[-1]):\n",
    "            for i_M in np.arange(B.shape[-1]):\n",
    "                C[:, :, i_N, i_M] = np_fftconvolve(A[:, :, i_N], B[:, :, i_M])                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A, B, C = get_data(N, n_N, M, n_M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "test_numpy_fft(A, B, C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A, B, C = get_data(N, n_N, M, n_M, prefetching=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "test_numpy_fft(A, B, C, prefetching=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Further profiling shows that most of the computing time is divided between the three FFT (2 forward, one inverse).\n",
    "\n",
    "This shows the advantage of using the Fourier transform to perform the convolution. There is also a slight advantage in using prefetching.\n",
    "\n",
    "From the design of the protocol, an optimization consists of computing the FFT transforms just once by using in-memory views of the different images and filters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A, B, C = get_data(N, n_N, M, n_M)\n",
    "from numpy.fft  import fft2, ifft2\n",
    "def test_numpy_fft_opt(A, B, prefetching=False):\n",
    "    if prefetching:\n",
    "        f_B = np.zeros((B.shape[0], A.shape[-2], A.shape[-1]), dtype=np.complex128)\n",
    "        for i_M in np.arange(B.shape[0]):\n",
    "            f_B[i_M, :, :] = fft2(B[i_M, :, :], s=A.shape[-2:])\n",
    "        \n",
    "        for i_N in np.arange(A.shape[0]):\n",
    "            f_A = fft2(A[i_N, :, :])\n",
    "            for i_M in np.arange(B.shape[0]):\n",
    "                C[i_N, i_M, :, :] = np.real(ifft2(f_A*f_B[i_M, :, :]))\n",
    "    else:\n",
    "        f_B = np.zeros((A.shape[0], A.shape[1], B.shape[-1]), dtype=np.complex128)\n",
    "        for i_M in np.arange(B.shape[-1]):\n",
    "            f_B[:, :, i_M] = fft2(B[:, :, i_M], s=A.shape[:2])\n",
    "        \n",
    "        for i_N in np.arange(A.shape[-1]):\n",
    "            f_A = fft2(A[:, :, i_N])\n",
    "            for i_M in np.arange(B.shape[-1]):\n",
    "                C[:, :, i_N, i_M] = np.real(ifft2(f_A*f_B[:, :, i_M]))\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A, B, C = get_data(N, n_N, M, n_M, prefetching=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "test_numpy_fft_opt(A, B, prefetching=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A, B, C = get_data(N, n_N, M, n_M, prefetching=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "test_numpy_fft_opt(A, B, prefetching=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# using ndimage\n",
    "\n",
    "Within ``scipy``, the ``ndimage`` library as different solutions:\n",
    "\n",
    "https://docs.scipy.org/doc/scipy/reference/generated/scipy.ndimage.correlate.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage import convolve\n",
    "# help(convolve)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage import convolve\n",
    "def test_ndimage(A, B, C, prefetching=False):\n",
    "    if prefetching:\n",
    "        for i_N in np.arange(A.shape[0]):\n",
    "            for i_M in np.arange(B.shape[0]):\n",
    "                C[i_N, i_M, :, :] = convolve(A[i_N, :, :], B[i_M, :, :], mode='constant', cval=0)\n",
    "    else:\n",
    "        for i_N in np.arange(A.shape[-1]):\n",
    "            for i_M in np.arange(B.shape[-1]):\n",
    "                C[:, :, i_N, i_M] = convolve(A[:, :, i_N], B[:, :, i_M], mode='constant', cval=0)                            \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A, B, C = get_data(N, n_N, M, n_M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "test_ndimage(A, B, C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A, B, C = get_data(N, n_N, M, n_M, prefetching=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "test_ndimage(A, B, C, prefetching=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is also a ``correlate`` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "from scipy.ndimage import correlate\n",
    "C = correlate(A, B[::-1, ::-1], mode='constant', cval=0) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# using skimage\n",
    "\n",
    "The ``skimage`` has recently grown in popularity and includes many advanced computer vision algorithms. This operator is quick (using the Fourier transform), while allowing for many convenient option (mode, boundaries):\n",
    "https://github.com/scikit-image/scikit-image/blob/master/skimage/feature/template.py\n",
    "\n",
    "Note: this function computes a normalized *correlation* so that you need to symmetrically invert the template to get the convolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.feature import match_template\n",
    "def test_skimage(A, B, C, prefetching=False):\n",
    "    if prefetching:\n",
    "        for i_N in np.arange(A.shape[0]):\n",
    "            for i_M in np.arange(B.shape[0]):\n",
    "                C[i_N, i_M, :, :] = match_template(A[i_N, :, :], B[i_M, :, :], pad_input=True, mode='constant', constant_values=0.)\n",
    "    else:\n",
    "        for i_N in np.arange(A.shape[-1]):\n",
    "            for i_M in np.arange(B.shape[-1]):\n",
    "                C[:, :, i_N, i_M] = match_template(A[:, :, i_N], B[:, :, i_M], pad_input=True, mode='constant', constant_values=0.)                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A, B, C = get_data(N, n_N, M, n_M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%timeit\n",
    "test_skimage(A, B, C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A, B, C = get_data(N, n_N, M, n_M, prefetching=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "test_skimage(A, B, C, prefetching=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# using numba\n",
    "\n",
    "The ``numba`` package allows access to very fast routine:\n",
    "http://numba.pydata.org/numba-doc/0.15.1/examples.html#filterbank-correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from __future__ import print_function, division, absolute_import\n",
    "import numpy as np\n",
    "import numba\n",
    "#from numba.utils import IS_PY3\n",
    "from numba.decorators import jit\n",
    "from numba import double\n",
    "#from numba import double, jit\n",
    "\n",
    "nd4type = numba.double[:,:,:,:]\n",
    "nd3type = numba.double[:,:,:]\n",
    "\n",
    "@jit(nopython=True)\n",
    "def nb_get_data(N=N, n_N=n_N, M=M, n_M=n_M, seed=42, prefetching=False):\n",
    "    np.random.seed(seed)\n",
    "    if prefetching:\n",
    "        A = np.random.rand(n_N, N, N)\n",
    "        B = np.random.rand(n_M, M, M)\n",
    "        C = np.zeros((n_N, n_M, N, N))\n",
    "    else:\n",
    "        A = np.random.rand(N, N, n_N)\n",
    "        B = np.random.rand(M, M, n_M)\n",
    "        C = np.zeros((N, N, n_N, n_M))\n",
    "    return A, B, C\n",
    "\n",
    "@jit((nd3type, nd3type, nd4type))\n",
    "def nbcorr_prefetching(imgs, filters, output):\n",
    "    n_imgs, n_rows, n_cols = imgs.shape\n",
    "    n_filters, height, width = filters.shape\n",
    "\n",
    "    for ii in range(n_imgs):\n",
    "        for rr in range(n_rows - height + 1):\n",
    "            for cc in range(n_cols - width + 1):\n",
    "                for hh in range(height):\n",
    "                    for ww in range(width):\n",
    "                        for ff in range(n_filters):\n",
    "                            imgval = imgs[ii, rr + hh, cc + ww]\n",
    "                            filterval = filters[ff, hh, ww]\n",
    "                            output[ii, ff, rr, cc] += imgval * filterval\n",
    "                            \n",
    "@jit((nd3type, nd3type, nd4type))                            \n",
    "def nbcorr(imgs, filters, output):\n",
    "    n_rows, n_cols, n_imgs = imgs.shape\n",
    "    height, width, n_filters = filters.shape\n",
    "\n",
    "    for ii in range(n_imgs):\n",
    "        for rr in range(n_rows - height + 1):\n",
    "            for cc in range(n_cols - width + 1):\n",
    "                for hh in range(height):\n",
    "                    for ww in range(width):\n",
    "                        for ff in range(n_filters):\n",
    "                            imgval = imgs[rr + hh, cc + ww, ii]\n",
    "                            filterval = filters[hh, ww, ff]\n",
    "                            output[rr, cc, ii, ff] += imgval * filterval\n",
    "                            \n",
    "def test_numba(A, B, C, prefetching=False):\n",
    "    if prefetching:\n",
    "        nbcorr_prefetching(A, B, C)\n",
    "    else:\n",
    "        nbcorr(A, B, C)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A, B, C = nb_get_data(N, n_N, M, n_M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%timeit\n",
    "test_numba(A, B, C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A, B, C = nb_get_data(N, n_N, M, n_M, prefetching=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "test_numba(A, B, C, prefetching=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There may be an advantage when processing multiple images at once:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A, B, C = nb_get_data(N=256, n_N=10, M=32, n_M=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%timeit\n",
    "test_numba(A, B, C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A, B, C = nb_get_data(N=256, n_N=10, M=32, n_M=10, prefetching=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "test_numba(A, B, C, prefetching=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "Seems promising as many ``numpy`` operations are supported : http://numba.pydata.org/numba-doc/dev/reference/numpysupported.html\n",
    "\n",
    "\n",
    "# using pytorch\n",
    "\n",
    "The ``pytorch`` package is currently used in deep-learning (DL) architectures, which also often rely on convolutions (for instance in CNNs):\n",
    "\n",
    "https://pytorch.org/docs/stable/nn.html#torch.nn.functional.conv2d\n",
    "\n",
    "\n",
    "A first advantage is that this convolution operator is optimized to handle multiple examples (mini-batches in DL terminology) over multiple filters (channels in DL), such that  there is no loop needed. The ordering of dimensions folloows a similar strategy as when using ``prefetching``: truy to remember ``(B, C, H, W)`` for respectively mini-batches, channels, height, width:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn.functional import conv2d\n",
    "\n",
    "filters = torch.randn(8, 4, 3, 3)\n",
    "inputs = torch.randn(10, 4, 5, 5)\n",
    "out = conv2d(inputs, filters, padding=1)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our benchmark, we have only one channel, but multiple batches:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A, B, C = get_data(N, n_N, M, n_M, prefetching=True)\n",
    "\n",
    "A = torch.from_numpy(A[:, None, :, :])\n",
    "B = torch.from_numpy(B[:, None, :, :])\n",
    "C = torch.from_numpy(C)\n",
    "A.shape, B.shape, C.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get a convolution of the same size, it is necessary to pad the filters (as for numpy). Note the padding is symmetric such that the size of the convolution is bigger than that for  numpy for instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = conv2d(A, B, padding=M//2)\n",
    "A.shape, B.shape, C.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_torch(A, B, prefetching=False):\n",
    "    if prefetching:\n",
    "        A = np.swapaxes(A, 0, -2)        \n",
    "        B = np.swapaxes(B, 0, -2)        \n",
    "        A = np.swapaxes(A, 1, -1)        \n",
    "        B = np.swapaxes(B, 1, -1)        \n",
    "    A = torch.from_numpy(A[:, None, :, :])\n",
    "    B = torch.from_numpy(B[:, None, :, :])\n",
    "    C = conv2d(A, B, padding=B.shape[-1]//2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A, B, C = get_data(N, n_N, M, n_M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%timeit\n",
    "test_torch(A, B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A, B, C = get_data(N, n_N, M, n_M, prefetching=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "test_torch(A, B, prefetching=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is faster than ``scipy_fft`` for instance. It is even faster on a GPU, which we do not include in that particular benchmark because it is difficult to compare it to the other methoss where no such solution exist."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# wrapping things up\n",
    "\n",
    "Now that we have an implementation for each library, it may be worth checking how they scale with respect to the different parameters:\n",
    "\n",
    "## number of images\n",
    "\n",
    "This should scale linearly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from timeit import Timer\n",
    "reps = 20\n",
    "sp, sk, nb, pt, npo = [], [], [], [], []\n",
    "n_Ns = 2**np.arange(6)\n",
    "\n",
    "for prefetching in [False, True]:\n",
    "    for n_N_ in n_Ns:\n",
    "        A, B, C = get_data(N, n_N_, M, n_M, prefetching=prefetching)\n",
    "        t = Timer(lambda: test_skimage(A, B, C, prefetching=prefetching))\n",
    "        sk.append(t.timeit(number=reps))\n",
    "        t = Timer(lambda: test_scipy_fft(A, B, C, prefetching=prefetching))\n",
    "        sp.append(t.timeit(number=reps))\n",
    "        t = Timer(lambda: test_numba(A, B, C, prefetching=prefetching))\n",
    "        nb.append(t.timeit(number=reps))\n",
    "        t = Timer(lambda: test_torch(A, B, prefetching=prefetching))\n",
    "        pt.append(t.timeit(number=reps))\n",
    "        t = Timer(lambda: test_numpy_fft_opt(A, B, prefetching=prefetching))\n",
    "        npo.append(t.timeit(number=reps))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig , ax = plt.subplots(figsize=(8, 5))\n",
    "ax.loglog(n_Ns, sk[:len(n_Ns)], c='b', label='skimage')\n",
    "ax.loglog(n_Ns, pt[:len(n_Ns)], c='c', label='torch')\n",
    "ax.loglog(n_Ns, nb[:len(n_Ns)], c='g', label='numba')\n",
    "ax.loglog(n_Ns, sp[:len(n_Ns)], c='r', label='scipy')\n",
    "ax.loglog(n_Ns, npo[:len(n_Ns)], c='m', label='numpy')\n",
    "ax.loglog(n_Ns, sk[len(n_Ns):], '--', c='b')\n",
    "ax.loglog(n_Ns, nb[len(n_Ns):], '--', c='g')\n",
    "ax.loglog(n_Ns, pt[len(n_Ns):], '--', c='c')\n",
    "ax.loglog(n_Ns, sp[len(n_Ns):], '--', c='r')\n",
    "ax.loglog(n_Ns, npo[len(n_Ns):], '--', c='m')\n",
    "ax.set_xlabel('n_N')\n",
    "ax.set_ylabel('time (s)')\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## size of images\n",
    "\n",
    "This should scale supra linearly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from timeit import Timer\n",
    "reps = 20\n",
    "sp, sk, nb, pt, npo = [], [], [], [], []\n",
    "Ns = 2**np.arange(6, 10)\n",
    "for prefetching in [False, True]:\n",
    "    for N_ in Ns:\n",
    "        A, B, C = get_data(N_, n_N, M, n_M, prefetching=prefetching)\n",
    "        t = Timer(lambda: test_skimage(A, B, C, prefetching=prefetching))\n",
    "        sk.append(t.timeit(number=reps))\n",
    "        t = Timer(lambda: test_scipy_fft(A, B, C, prefetching=prefetching))\n",
    "        sp.append(t.timeit(number=reps))\n",
    "        t = Timer(lambda: test_numba(A, B, C, prefetching=prefetching))\n",
    "        nb.append(t.timeit(number=reps))\n",
    "        t = Timer(lambda: test_torch(A, B, prefetching=prefetching))\n",
    "        pt.append(t.timeit(number=reps))\n",
    "        t = Timer(lambda: test_numpy_fft_opt(A, B, prefetching=prefetching))\n",
    "        npo.append(t.timeit(number=reps))\n",
    "\n",
    "fig , ax = plt.subplots(figsize=(8, 5))\n",
    "ax.loglog(Ns, sk[:len(Ns)], c='b', label='skimage')\n",
    "ax.loglog(Ns, nb[:len(Ns)], c='g', label='numba')\n",
    "ax.loglog(Ns, pt[:len(Ns)], c='c', label='torch')\n",
    "ax.loglog(Ns, sp[:len(Ns)], c='r', label='scipy')\n",
    "ax.loglog(Ns, npo[:len(Ns)], c='m', label='numpy')\n",
    "ax.loglog(Ns, sp[len(Ns):], '--', c='r')\n",
    "ax.loglog(Ns, sk[len(Ns):], '--', c='b')\n",
    "ax.loglog(Ns, nb[len(Ns):], '--', c='g')\n",
    "ax.loglog(Ns, pt[len(Ns):], '--', c='c')\n",
    "ax.loglog(Ns, npo[len(Ns):], '--', c='m')\n",
    "ax.set_xlabel('N')\n",
    "ax.set_ylabel('time (s)')\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## number of kernels\n",
    "\n",
    "This should scale supra linearly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from timeit import Timer\n",
    "reps = 20\n",
    "sp, sk, nb, pt, npo = [], [], [], [], []\n",
    "n_Ms = 2**np.arange(6)\n",
    "\n",
    "for prefetching in [False, True]:\n",
    "    for n_M_ in n_Ms:\n",
    "        A, B, C = get_data(N, n_N, M, n_M_, prefetching=prefetching)\n",
    "        t = Timer(lambda: test_skimage(A, B, C, prefetching=prefetching))\n",
    "        sk.append(t.timeit(number=reps))\n",
    "        t = Timer(lambda: test_scipy_fft(A, B, C, prefetching=prefetching))\n",
    "        sp.append(t.timeit(number=reps))\n",
    "        t = Timer(lambda: test_numba(A, B, C, prefetching=prefetching))\n",
    "        nb.append(t.timeit(number=reps))\n",
    "        t = Timer(lambda: test_torch(A, B, prefetching=prefetching))\n",
    "        pt.append(t.timeit(number=reps))        \n",
    "        t = Timer(lambda: test_numpy_fft_opt(A, B, prefetching=prefetching))\n",
    "        npo.append(t.timeit(number=reps))\n",
    "    \n",
    "fig , ax = plt.subplots(figsize=(8, 5))\n",
    "ax.loglog(n_Ms, sp[:len(n_Ms)], c='r', label='scipy')\n",
    "ax.loglog(n_Ms, sk[:len(n_Ms)], c='b', label='skimage')\n",
    "ax.loglog(n_Ms, nb[:len(n_Ms)], c='g', label='numba')\n",
    "ax.loglog(n_Ms, pt[:len(n_Ms)], c='c', label='torch')\n",
    "ax.loglog(n_Ms, npo[:len(n_Ms)], c='m', label='numpy')\n",
    "ax.loglog(n_Ms, sp[len(n_Ms):], '--', c='r')\n",
    "ax.loglog(n_Ms, sk[len(n_Ms):], '--', c='b')\n",
    "ax.loglog(n_Ms, nb[len(n_Ms):], '--', c='g')\n",
    "ax.loglog(n_Ms, pt[len(n_Ms):], '--', c='c')\n",
    "ax.loglog(n_Ms, npo[len(n_Ms):], '--', c='m')\n",
    "ax.set_xlabel('n_M')\n",
    "ax.set_ylabel('time (s)')\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## size of kernels\n",
    "\n",
    "This should scale supra linearly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from timeit import Timer\n",
    "reps = 20\n",
    "sp, sk, nb, pt, npo = [], [], [], [], []\n",
    "Ms = 2**np.arange(2, 7)\n",
    "\n",
    "for prefetching in [False, True]:\n",
    "    for M_ in Ms:\n",
    "        A, B, C = get_data(N, n_N, M_, n_M, prefetching=prefetching)\n",
    "        t = Timer(lambda: test_skimage(A, B, C, prefetching=prefetching))\n",
    "        sk.append(t.timeit(number=reps))\n",
    "        t = Timer(lambda: test_scipy_fft(A, B, C, prefetching=prefetching))\n",
    "        sp.append(t.timeit(number=reps))\n",
    "        t = Timer(lambda: test_numba(A, B, C, prefetching=prefetching))\n",
    "        nb.append(t.timeit(number=reps))\n",
    "        t = Timer(lambda: test_torch(A, B, prefetching=prefetching))\n",
    "        pt.append(t.timeit(number=reps))        \n",
    "        t = Timer(lambda: test_numpy_fft_opt(A, B, prefetching=prefetching))\n",
    "        npo.append(t.timeit(number=reps))\n",
    "    \n",
    "fig , ax = plt.subplots(figsize=(8, 5))\n",
    "ax.loglog(Ms, sp[:len(Ms)], c='r', label='scipy')\n",
    "ax.loglog(Ms, sk[:len(Ms)], c='b', label='skimage')\n",
    "ax.loglog(Ms, nb[:len(Ms)], c='g', label='numba')\n",
    "ax.loglog(Ms, pt[:len(Ms)], c='c', label='torch')\n",
    "ax.loglog(Ms, npo[:len(Ms)], c='m', label='numpy')\n",
    "ax.loglog(Ms, sp[len(Ms):], '--', c='r')\n",
    "ax.loglog(Ms, sk[len(Ms):], '--', c='b')\n",
    "ax.loglog(Ms, nb[len(Ms):], '--', c='g')\n",
    "ax.loglog(Ms, pt[len(Ms):], '--', c='c')\n",
    "ax.loglog(Ms, npo[len(Ms):], '--', c='m')\n",
    "ax.set_xlabel('M')\n",
    "ax.set_ylabel('time (s)')\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## conclusion?\n",
    "\n",
    "As a conclusion, there is not one single answer to all situations, the fastest method will depend on the task at hand. This benchmark needs to be extended to the case where you have access to a GPU for which the parallelization should make convolutions faster with ``pytorch``(in theory). Still, the FFT solution with ``numpy`` seems the most rapid.  Overall, there is also a slight advantage in using prefetching.\n",
    "In the end, knowing the relative advantage of each library is crucial in the final result.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## some book keeping for the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-07T16:19:23.177738Z",
     "start_time": "2018-11-07T16:19:23.125993Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext watermark\n",
    "%watermark -i -h -m -v -p numpy,scipy,matplotlib,torch,numba  -r -g -b"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "207px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
